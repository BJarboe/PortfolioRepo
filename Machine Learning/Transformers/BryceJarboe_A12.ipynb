{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "567c8c78-ca40-4e15-b209-5919c212d816",
   "metadata": {},
   "source": [
    "# CS549 Machine Learning - Irfan Khan\n",
    "# Assignment 11: Transformer and Transformer-based Models\n",
    "\n",
    "Updated Assignment designed by Yang Xu, Ex-Assistant Professor of Computer Science, San Diego State University\n",
    "\n",
    "**Total points: 15**\n",
    "\n",
    "In this assignment, you will do two things: \n",
    "1) Implement the **multiple head attention** sub layer in a transformer encoder.\n",
    "2) Play with the transformer-based models provided in **transformers** for multiple natural language processing (NLP) tasks.\n",
    "\n",
    "https://colab.research.google.com/drive/1rPk3ohrmVclqhH7uQ7qys4oznDdAhpzF#scrollTo=jUTNr15JBkSG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ab56b",
   "metadata": {},
   "source": [
    "# Import Libraries and set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "238c9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.special import softmax\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"   # This is just for my end, messed up my installs\n",
    "\n",
    "#print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8609f3cf-1550-46b4-932e-c7a81191042e",
   "metadata": {},
   "source": [
    "## Task 1. Implement the multiple head attention sub layer\n",
    "**Total Points: 8**\n",
    "\n",
    "### 1.1 Initialize input data\n",
    "\n",
    "***1 point***<br>\n",
    "Step 1, generate some random input data in the shape of ${m_{inputs}} x {d_{model}}$. *Hint*: Use `np.random.rand()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "087a8163-c41b-40b1-86ee-fe4ba8a967d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # Do not remove this line\n",
    "\n",
    "d_model = 512\n",
    "m_inputs = 3\n",
    "\n",
    "### START YOUR CODE ###\n",
    "x = np.random.rand(m_inputs, d_model)\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a5c43b-4f12-445f-bc9e-eef841dd206e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[0.5488135  0.71518937 0.60276338 ... 0.44613551 0.10462789 0.34847599]\n",
      " [0.74009753 0.68051448 0.62238443 ... 0.6204999  0.63962224 0.9485403 ]\n",
      " [0.77827617 0.84834527 0.49041991 ... 0.07382628 0.49096639 0.7175595 ]]\n",
      "x.shape: (3, 512)\n"
     ]
    }
   ],
   "source": [
    "# Do not change the code in this cell\n",
    "print('x:', x)\n",
    "print('x.shape:', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24cce1-8f70-4944-ba17-36f45a62a1a4",
   "metadata": {},
   "source": [
    "**Expected output**\\\n",
    "x: [[0.5488135  0.71518937 0.60276338 ... 0.44613551 0.10462789 0.34847599]\\\n",
    " [0.74009753 0.68051448 0.62238443 ... 0.6204999  0.63962224 0.9485403 ]\\\n",
    " [0.77827617 0.84834527 0.49041991 ... 0.07382628 0.49096639 0.7175595 ]]\\\n",
    "x.shape: (3, 512)\n",
    "\n",
    "---\n",
    "### 1.2 Create weight matrices for *query*, *key*, and *value*\n",
    "\n",
    "***2 points***\n",
    "\n",
    "Step 2, create the weight matrices into the correct dimensions. \n",
    "\n",
    "Let's start with `W_query` and `Q`. *Hint*: We first initialize an empty tensor `W` in the dimension of `(d_model, d_k)`, using the `torch.empty()` function. Then we initialize it with `nn.init.xavier_uniform_()`.\n",
    "\n",
    "After `W_query` is initialized, we can get the query matrix `Q` with a multiplication between `x` and `W_query`. *Hint*: Use `np.matmul()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2417e097-dc26-4560-aadb-6cf6538a5d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0) # Do not remove this line\n",
    "\n",
    "n_heads = 8\n",
    "d_k = d_model // n_heads #Integer division\n",
    "\n",
    "### START YOUR CODE ###\n",
    "# Create an empty tensor W with the correct dimension.\n",
    "W = torch.empty((d_model, d_k))\n",
    "### END YOUR CODE ###\n",
    "\n",
    "nn.init.xavier_uniform_(W) # Randomly initialize the values in the tensor.\n",
    "W_query = W.data.numpy() # Copy out the numpy array\n",
    "\n",
    "### START YOUR CODE ###\n",
    "#Hint: use np.matmul()\n",
    "Q = np.matmul(x, W_query)\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e37723c-b393-4447-a33e-3de448f6ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_query[0,:5]: [-0.00076412  0.05475055 -0.0840017  -0.07511146 -0.03930965]\n",
      "W_query.shape: (512, 64)\n",
      "Q[0, :5]: [-0.22772415  0.48167861  1.48693408 -1.00410576  0.19323685]\n",
      "Q.shape: (3, 64)\n"
     ]
    }
   ],
   "source": [
    "# Do not change the code in this cell\n",
    "print('W_query[0,:5]:', W_query[0,:5])\n",
    "print('W_query.shape:', W_query.shape)\n",
    "print('Q[0, :5]:', Q[0,:5])\n",
    "print('Q.shape:', Q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab6588-bf20-4ec2-9e6f-31d31a8a1607",
   "metadata": {},
   "source": [
    "**Expected output**\\\n",
    "W_query[0,:5]: [-0.00076412  0.05475055 -0.0840017  -0.07511146 -0.03930965]\\\n",
    "W_query.shape: (512, 64)\\\n",
    "Q[0, :5]: [-0.22772415  0.48167861  1.48693408 -1.00410576  0.19323685]\\\n",
    "Q.shape: (3, 64)\n",
    "\n",
    "---\n",
    "Next, repeat for `W_key` & `K`, and `W_value` & `V`.\n",
    "\n",
    "***2 points, 1 point for each of the two below cells***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f56e2283-ef60-440c-9b7e-ce21a9eede97",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1) # Do not remove this line\n",
    "\n",
    "### START YOUR CODE ###\n",
    "\n",
    "### END YOUR CODE ###\n",
    "\n",
    "nn.init.xavier_uniform_(W)\n",
    "W_key = W.data.numpy()\n",
    "\n",
    "### START YOUR CODE ###\n",
    "K = np.matmul(x, W_key)\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33f747fd-2e13-4bbb-b59d-c5b0abec134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2) # Do not remove this line\n",
    "\n",
    "### START YOUR CODE ###\n",
    "\n",
    "### END YOUR CODE ###\n",
    "\n",
    "nn.init.xavier_uniform_(W)\n",
    "W_value = W.data.numpy()\n",
    "\n",
    "### START YOUR CODE ###\n",
    "V = np.matmul(x, W_value)\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6fba58b-6162-42e1-a17b-fa7ddb1ca423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K[0,:5] [ 0.2283654  -0.65482728 -0.07202067  0.49886374  0.57045028]\n",
      "K.shape (3, 64)\n",
      "V[0,:5] [-0.44997754  0.92097362 -0.76932045  0.03289757 -0.49462588]\n",
      "V.shape (3, 64)\n"
     ]
    }
   ],
   "source": [
    "# Do not change the code in this cell\n",
    "print('K[0,:5]', K[0,:5])\n",
    "print('K.shape', K.shape)\n",
    "print('V[0,:5]', V[0,:5])\n",
    "print('V.shape', V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e3f72c-5fae-41e3-b1aa-f8247f691694",
   "metadata": {},
   "source": [
    "**Expected output**\\\n",
    "K[0,:5] [ 0.2283654  -0.65482728 -0.07202067  0.49886374  0.57045028]\\\n",
    "K.shape (3, 64)\\\n",
    "V[0,:5] [-0.44997754  0.92097362 -0.76932045  0.03289757 -0.49462588]\\\n",
    "V.shape (3, 64)\n",
    "\n",
    "---\n",
    "### 1.3 Compute attention scores and weighted output\n",
    "\n",
    "***2 points***\n",
    "\n",
    "Step 3, compute the attention scores using the matrices `Q` and `K`, following the equation:\n",
    "\n",
    "\\begin{equation}\n",
    "Attention(Q, K) = softmax(\\frac{Q\\cdot K^T}{\\sqrt{d_k}})\n",
    "\\end{equation}\n",
    "\n",
    "in which $\\sqrt{d_k}$ is for normalization purpose.\n",
    "\n",
    "*Hint*: You should first compute `attn_scores`, which is the unnormalized score. Then you can apply the `softmax()` function imported from `scipy` to calculate the normalized scores. Note that you need to specify the `axis` argument correctly when you call `softmax()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77b2bf0c-b3d2-4598-affd-b041cc855348",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "attn_scores = np.dot(Q,K.T) / np.sqrt(d_k)\n",
    "### END YOUR CODE ###\n",
    "\n",
    "### START YOUR CODE ###\n",
    "# compute attn_scores_norm\n",
    "attn_scores_norm = softmax(attn_scores, axis=1)\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbca70a3-3b71-4c21-a8e0-d28dfe1eb30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_scores.shape: (3, 3)\n",
      "Unnormalized attn_scores: [[-0.75497307 -0.97036233 -0.85112729]\n",
      " [ 0.23777018 -0.70730381 -0.37639239]\n",
      " [ 0.21608578 -0.73905372 -0.89881112]]\n",
      "Normalized atten_scores: [[0.36838498 0.29700212 0.33461289]\n",
      " [0.51820328 0.20140013 0.2803966 ]\n",
      " [0.58387084 0.22464925 0.19147991]]\n"
     ]
    }
   ],
   "source": [
    "# Do not change the code in this cell\n",
    "print('attn_scores.shape:', attn_scores.shape)\n",
    "print('Unnormalized attn_scores:', attn_scores)\n",
    "print('Normalized atten_scores:', attn_scores_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762525c0-8837-4713-8957-7b8a3d8cea8c",
   "metadata": {},
   "source": [
    "**Expected output**\\\n",
    "attn_scores.shape: (3, 3)\\\n",
    "Unnormalized attn_scores: [[-0.75497307 -0.97036233 -0.85112729]\\\n",
    " [ 0.23777018 -0.70730381 -0.37639239]\\\n",
    " [ 0.21608578 -0.73905372 -0.89881112]]\\\n",
    "Normalized atten_scores: [[0.36838498 0.29700212 0.33461289]\\\n",
    " [0.51820328 0.20140013 0.2803966 ]\\\n",
    " [0.58387084 0.22464925 0.19147991]]\\\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4\n",
    "***1 point***<br>\n",
    "Finally, compute the output as the weighted sum of value (`V`), using the above computed `attn_scores_norm` as the weight.\n",
    "\n",
    "*Hint*: `attn_scores_norm[0,:]` is the weight for the first output `weighted_output[0,:]`, \\\n",
    "so the computation is:\\\n",
    "`weighted_output[0,:] = attn_scores_norm[0,0] * V[0,:] + attn_scores_norm[0,1] * V[1,:] + attn_scores_norm[0,2] * V[2,:]`. \\\n",
    "But you can achieve this with one line code using `@`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4adf620e-2c6e-48d3-a59f-75151d743e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted_output[0,:5]: [-0.37040031  0.493314   -0.78595572  0.09711595 -0.33551551]\n",
      "weighted_output.shape: (3, 64)\n"
     ]
    }
   ],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "weighted_output = np.dot(attn_scores_norm, V)\n",
    "### END YOUR CODE ###\n",
    "\n",
    "# Do not change the code below\n",
    "print('weighted_output[0,:5]:', weighted_output[0,:5])\n",
    "print('weighted_output.shape:', weighted_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed38400",
   "metadata": {},
   "source": [
    "**Expected output**\\\n",
    "weighted_output[0,:5]: [-0.37040031  0.493314   -0.78595572  0.09711595 -0.33551551]\\\n",
    "weighted_output.shape: (3, 64)\n",
    "\n",
    "---\n",
    "**Congratulations!** You have finished Task 1, and now you know how to implement the self-attention module, which is the core technique of Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d326f0",
   "metadata": {},
   "source": [
    "## Task 2. Play with transformer-based models\n",
    "**Points: 7**\n",
    "\n",
    "### 2.1 Installation\n",
    "If not already installed, install the *transformers* package \n",
    "\n",
    "After it is done, you can load some pretrained BERT models and tokenizers like this (you can ignore the warnings):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5837f8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faeb6b1277e341da97e4657ce70eb030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bryce\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bryce\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0717010b2ba94da5ac5b28d8e86842b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5310297d5974cf78eefd18617988626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ccedd4bc5140f6b57a42c33fd26d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ee8eccbd9d46c189760ba7dc843709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890048a4",
   "metadata": {},
   "source": [
    "### 2.2 Tokenizing inputs\n",
    "\n",
    "Run the following examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a76f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n",
      "torch.Size([1, 275])\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"The hotness of the sun and the coldness of the outer space are inexhaustible thermodynamic\n",
    "resources for human beings. From a thermodynamic point of view, any energy conversion systems\n",
    "that receive energy from the sun and/or dissipate energy to the universe are heat engines with\n",
    "photons as the \"working fluid\" and can be analyzed using the concept of entropy. While entropy\n",
    "analysis provides a particularly convenient way to understand the efficiency limits, it is typically\n",
    "taught in the context of thermodynamic cycles among quasi-equilibrium states and its\n",
    "generalization to solar energy conversion systems running in a continuous and non-equilibrium\n",
    "fashion is not straightforward. In this educational article, we present a few examples to illustrate\n",
    "how the concept of photon entropy, combined with the radiative transfer equation, can be used to\n",
    "analyze the local entropy generation processes and the efficiency limits of different solar energy\n",
    "conversion systems. We provide explicit calculations for the local and total entropy generation\n",
    "rates for simple emitters and absorbers, as well as photovoltaic cells, which can be readily\n",
    "reproduced by students. We further discuss the connection between the entropy generation and the\n",
    "device efficiency, particularly the exact spectral matching condition that is shared by infinitejunction photovoltaic cells and reversible thermoelectric materials to approach their theoretical\n",
    "efficiency limit.\"\"\"\n",
    "\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "print(len(text.split()))\n",
    "print(encoded_input['input_ids'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1678938f",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "\n",
    "211<br>\n",
    "torch.Size([1, 275])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b2435",
   "metadata": {},
   "source": [
    "Can you explain why the `encoded_input` has more elements than the actual number of words in `text`?\\\n",
    "(**Points: 2**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ad567",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your answer within the quotes ###\n",
    "answer = \"\"\"\n",
    "It interperets not only words but also 'sub-words' where it breaks down the words into parts that may convey more information\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b2f5c",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 2.3 Output word vectors from BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae98bf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 275, 768])\n"
     ]
    }
   ],
   "source": [
    "output = model(**encoded_input)\n",
    "\n",
    "last_hidden_state = output['last_hidden_state']\n",
    "\n",
    "print(last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a867827",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "\n",
    "torch.Size([1, 275, 768])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d5b54",
   "metadata": {},
   "source": [
    "With the following code, you can find the corresponding token of each integer id in `input_ids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c972b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1996, 2980, 2791, 1997, 1996, 3103, 1998, 1996, 3147]\n",
      "['[CLS]', 'the', 'hot', '##ness', 'of', 'the', 'sun', 'and', 'the', 'cold']\n"
     ]
    }
   ],
   "source": [
    "input_ids_pt = encoded_input['input_ids']\n",
    "input_ids_list = input_ids_pt.tolist()[0]\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(input_ids_list)\n",
    "\n",
    "print(input_ids_list[:10])\n",
    "print(input_tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b6094d",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "\n",
    "[101, 1996, 2980, 2791, 1997, 1996, 3103, 1998, 1996, 3147]<br>\n",
    "['[CLS]', 'the', 'hot', '##ness', 'of', 'the', 'sun', 'and', 'the', 'cold']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0bca8",
   "metadata": {},
   "source": [
    "Can you find the output vector**s** among `last_hidden_state` that correpond to the input word \"entropy\"?\\\n",
    "Do they have the same values?\\\n",
    "**(Points: 2)**\n",
    "\n",
    "*Hint*: You can use a `if` statement to check if the current token is the word \"entropy\", and if so, you can append it to `vectors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a589a476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of \"entropy\": 6\n",
      "Do they have the same value? [False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "vectors = []\n",
    "for i, token in enumerate(input_tokens):\n",
    "    ### START YOUR CODE ###\n",
    "    if input_tokens[i] == \"entropy\":\n",
    "        vectors.append(last_hidden_state[0,i])\n",
    "    ### END YOUR CODE ###\n",
    "# Do not change the code below\n",
    "print('Number of \"entropy\":', len(vectors))\n",
    "\n",
    "matches = [torch.allclose(vectors[i], vectors[i+1]) for i in range(len(vectors)-1)]\n",
    "print(f'Do they have the same value? {matches}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec441f18",
   "metadata": {},
   "source": [
    "**Expected output:** \\\n",
    "Number of \"entropy\": 6\\\n",
    "Do they have the same value? [False, False, False, False, False]\n",
    "\n",
    "---\n",
    "### 2.4 Sentence vectors from BERT\n",
    "\n",
    "We can obtain the output vectors for a batch of sentences.\n",
    "\n",
    "First, we need to break the text into a list of sentences, using a simple end-of-sentence str '.' as a separater. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27548d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting in 6 sentences:\n",
      "['The hotness of the sun and the coldness of the outer space are inexhaustible thermodynamic resources for human beings.', 'From a thermodynamic point of view, any energy conversion systems that receive energy from the sun and/or dissipate energy to the universe are heat engines with photons as the \"working fluid\" and can be analyzed using the concept of entropy.', 'While entropy analysis provides a particularly convenient way to understand the efficiency limits, it is typically taught in the context of thermodynamic cycles among quasi-equilibrium states and its generalization to solar energy conversion systems running in a continuous and non-equilibrium fashion is not straightforward.', 'In this educational article, we present a few examples to illustrate how the concept of photon entropy, combined with the radiative transfer equation, can be used to analyze the local entropy generation processes and the efficiency limits of different solar energy conversion systems.', 'We provide explicit calculations for the local and total entropy generation rates for simple emitters and absorbers, as well as photovoltaic cells, which can be readily reproduced by students.', 'We further discuss the connection between the entropy generation and the device efficiency, particularly the exact spectral matching condition that is shared by infinitejunction photovoltaic cells and reversible thermoelectric materials to approach their theoretical efficiency limit.']\n"
     ]
    }
   ],
   "source": [
    "sentences = text.replace('\\n', ' ').split('.')\n",
    "sentences = [s.strip() + '.' for s in sentences if len(s.strip())>0] # Some cleaning work\n",
    "\n",
    "print(f'Resulting in {len(sentences)} sentences:')\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f834c3",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "\n",
    "Resulting in 6 sentences:<br>\n",
    "['The hotness of the sun and the coldness of the outer space are inexhaustible thermodynamic resources for human beings.', 'From a thermodynamic point of view, any energy conversion systems that receive energy from the sun and/or dissipate energy to the universe are heat engines with photons as the \"working fluid\" and can be analyzed using the concept of entropy.', 'While entropy analysis provides a particularly convenient way to understand the efficiency limits, it is typically taught in the context of thermodynamic cycles among quasi-equilibrium states and its generalization to solar energy conversion systems running in a continuous and non-equilibrium fashion is not straightforward.', 'In this educational article, we present a few examples to illustrate how the concept of photon entropy, combined with the radiative transfer equation, can be used to analyze the local entropy generation processes and the efficiency limits of different solar energy conversion systems.', 'We provide explicit calculations for the local and total entropy generation rates for simple emitters and absorbers, as well as photovoltaic cells, which can be readily reproduced by students.', 'We further discuss the connection between the entropy generation and the device efficiency, particularly the exact spectral matching condition that is shared by infinitejunction photovoltaic cells and reversible thermoelectric materials to approach their theoretical efficiency limit.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8572f9",
   "metadata": {},
   "source": [
    "Now, let's use tokenizer on this batch of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "655edd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 57])\n",
      "tensor([  101,  1996,  2980,  2791,  1997,  1996,  3103,  1998,  1996,  3147,\n",
      "         2791,  1997,  1996,  6058,  2686,  2024,  1999, 10288, 13821,  3775,\n",
      "         3468,  1996, 10867,  7716, 18279,  7712,  4219,  2005,  2529,  9552,\n",
      "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0])\n",
      "tensor([  101,  2013,  1037,  1996, 10867,  7716, 18279,  7712,  2391,  1997,\n",
      "         3193,  1010,  2151,  2943,  7584,  3001,  2008,  4374,  2943,  2013,\n",
      "         1996,  3103,  1998,  1013,  2030,  4487, 18719, 17585,  2943,  2000,\n",
      "         1996,  5304,  2024,  3684,  5209,  2007, 26383,  2015,  2004,  1996,\n",
      "         1000,  2551,  8331,  1000,  1998,  2064,  2022, 16578,  2478,  1996,\n",
      "         4145,  1997, 23077,  1012,   102,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "encoded_sentences = tokenizer(sentences, padding=True, return_tensors='pt')\n",
    "\n",
    "print(encoded_sentences['input_ids'].shape)\n",
    "print(encoded_sentences['input_ids'][0,:])\n",
    "print(encoded_sentences['input_ids'][1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d9d81f",
   "metadata": {},
   "source": [
    "You can find that shorter sentences are padded with a special id `0`.\n",
    "\n",
    "Next, we can obtain the output tensors for all input sentences, also in a batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972aa099",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "\n",
    "torch.Size([6, 57])<br>\n",
    "tensor([  101,  1996,  2980,  2791,  1997,  1996,  3103,  1998,  1996,  3147,\n",
    "         2791,  1997,  1996,  6058,  2686,  2024,  1999, 10288, 13821,  3775,\n",
    "         3468,  1996, 10867,  7716, 18279,  7712,  4219,  2005,  2529,  9552,\n",
    "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0])<br>\n",
    "tensor([  101,  2013,  1037,  1996, 10867,  7716, 18279,  7712,  2391,  1997,\n",
    "         3193,  1010,  2151,  2943,  7584,  3001,  2008,  4374,  2943,  2013,\n",
    "         1996,  3103,  1998,  1013,  2030,  4487, 18719, 17585,  2943,  2000,\n",
    "         1996,  5304,  2024,  3684,  5209,  2007, 26383,  2015,  2004,  1996,\n",
    "         1000,  2551,  8331,  1000,  1998,  2064,  2022, 16578,  2478,  1996,\n",
    "         4145,  1997, 23077,  1012,   102,     0,     0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "289ebaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 57, 768])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**encoded_sentences)\n",
    "\n",
    "print(outputs['last_hidden_state'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4697612",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "\n",
    "torch.Size([6, 57, 768])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35177ce",
   "metadata": {},
   "source": [
    "Note that the first dimension of `outputs['last_hidden_state']` is batch size. So the output tensor for the 1st sentence is `outputs['last_hidden_state'][0]`, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7c2f88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([57, 768])\n"
     ]
    }
   ],
   "source": [
    "print(outputs['last_hidden_state'][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ec299c",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "\n",
    "torch.Size([57, 768])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc0beab",
   "metadata": {},
   "source": [
    "For each output tensor, the first 768-dim vector (at position 0) always corresponds to the special input token `[CLS]`. We can use this vector to represent the meaning of the whole sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54b83a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "CLS_vec = outputs['last_hidden_state'][0][0]\n",
    "print(CLS_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3c790e",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "\n",
    "torch.Size([768])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49440369",
   "metadata": {},
   "source": [
    "Now, it is your task to compute the cosine similarities between each pair of the 6 sentences, and find the pair that has the closest meanings.\\\n",
    "**(Points: 3)**\n",
    "\n",
    "*Hint*: You can use the `cosine_similarity()` function imported at the beginning, which takes input two tensors and returns the similarity score in a tensor. So you will need to append a `.item()` to retrieve the numeric value from the returned tensor. You also need to specify the argument `dim=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af90868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <-> 1: 0.8591638803482056\n",
      "0 <-> 2: 0.7771982550621033\n",
      "0 <-> 3: 0.7985226511955261\n",
      "0 <-> 4: 0.7754688262939453\n",
      "0 <-> 5: 0.8052164316177368\n",
      "1 <-> 2: 0.8763416409492493\n",
      "1 <-> 3: 0.8321618437767029\n",
      "1 <-> 4: 0.823844850063324\n",
      "1 <-> 5: 0.8492751717567444\n",
      "2 <-> 3: 0.8241373896598816\n",
      "2 <-> 4: 0.859862744808197\n",
      "2 <-> 5: 0.8579832911491394\n",
      "3 <-> 4: 0.9018082618713379\n",
      "3 <-> 5: 0.9291439056396484\n",
      "4 <-> 5: 0.918526828289032\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for j in range(i+1, 6):\n",
    "        ### START YOUR CODE ###\n",
    "        sim = cosine_similarity(outputs['last_hidden_state'][i][0], outputs['last_hidden_state'][j][0], dim=0).item()\n",
    "        # Hint: when you call cosine_similarity() function for \"sim\", remember to specify dim=0. \n",
    "        #Also, you need append .item() at the end to obtain a number instead of a tensor.\n",
    "        ### END YOUR CODE ###\n",
    "        print(f'{i} <-> {j}: {sim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80331f5d",
   "metadata": {},
   "source": [
    "**Expected output:**\\\n",
    "0 <-> 1: 0.8591639399528503\\\n",
    "0 <-> 2: 0.777198314666748\\\n",
    "0 <-> 3: 0.7985224723815918\\\n",
    "0 <-> 4: 0.7754684090614319\\\n",
    "0 <-> 5: 0.8052163124084473\\\n",
    "1 <-> 2: 0.876341700553894\\\n",
    "1 <-> 3: 0.8321619629859924\\\n",
    "1 <-> 4: 0.823844850063324\\\n",
    "1 <-> 5: 0.8492751717567444\\\n",
    "2 <-> 3: 0.8241377472877502\\\n",
    "2 <-> 4: 0.8598626852035522\\\n",
    "2 <-> 5: 0.8579834699630737\\\n",
    "3 <-> 4: 0.9018082618713379\\\n",
    "3 <-> 5: 0.929144024848938\\\n",
    "4 <-> 5: 0.9185266494750977\n",
    "\n",
    "---\n",
    "You can print out the two sentences to see if the similarity score makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d29f7035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this educational article, we present a few examples to illustrate how the concept of photon entropy, combined with the radiative transfer equation, can be used to analyze the local entropy generation processes and the efficiency limits of different solar energy conversion systems.\n",
      "We further discuss the connection between the entropy generation and the device efficiency, particularly the exact spectral matching condition that is shared by infinitejunction photovoltaic cells and reversible thermoelectric materials to approach their theoretical efficiency limit.\n"
     ]
    }
   ],
   "source": [
    "print(sentences[3])\n",
    "print(sentences[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4afcfe",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "\n",
    "In this educational article, we present a few examples to illustrate how the concept of photon entropy, combined with the radiative transfer equation, can be used to analyze the local entropy generation processes and the efficiency limits of different solar energy conversion systems.<br>\n",
    "We further discuss the connection between the entropy generation and the device efficiency, particularly the exact spectral matching condition that is shared by infinitejunction photovoltaic cells and reversible thermoelectric materials to approach their theoretical efficiency limit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55802ab5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.5 Play with summarization\n",
    "\n",
    "Let's play with the summarization pipeline provided by transformers. Be patient when the model is downloading. \n",
    "\n",
    "You can try the following code with different input text or arguments. Ignore warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "790cc832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b738029d1a3b44ef91da8826647b87bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bryce\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bryce\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3b9f369f2a41758ecd3bea5f0e9242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab4519ca0a84fd2a12c72944af9d837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd514925fa2e4527b488b642a2c09fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970e77675e4f421781ead6d546c2b809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' The hotness of the sun and the coldness of outer space are inexhaustible thermodynamic resources for human beings . From a thermodynamic point of view, any energy conversion systems that receive energy from the sun or dissipate energy to the universe are heat engines with photons as the \"working fluid\"'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "print(summarizer(text, max_length=150, min_length=30))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b412cf",
   "metadata": {},
   "source": [
    "### Expected Result\n",
    "\n",
    "\n",
    "Ignore any warnings. Will take some time to run.<br><br>\n",
    "[{'summary_text': ' The hotness of the sun and the coldness of outer space are inexhaustible thermodynamic resources for human beings . From a thermodynamic point of view, any energy conversion systems that receive energy from the sun or dissipate energy to the universe are heat engines with photons as the \"working fluid\"'}]<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320cad5b",
   "metadata": {},
   "source": [
    "### 2.6 Play with Sentiment Analysis\n",
    "\n",
    "Let's play with the Sentiment Analysis pipeline provided by transformers. Be patient when the model is downloading. \n",
    "\n",
    "You can try the following code with different input text or arguments. Ignore warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d0c0bcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495d3b28c1c44d9fb56f2df59c0abf9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bryce\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bryce\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deaa63745e6044f483fa4b3dfcc9cd85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea716ec4e02946549babc9f511eefa4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ebf101c80aa42a3ab9c714d399fb69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9984171390533447}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.999295711517334}]\n"
     ]
    }
   ],
   "source": [
    "sentiment_classifier = pipeline(\"sentiment-analysis\")\n",
    "text2 = \"I love using transformers library for natural language processing!\"\n",
    "\n",
    "# Perform sentiment classification\n",
    "result = sentiment_classifier(text2)\n",
    "\n",
    "# Output the result\n",
    "print(result)\n",
    "\n",
    "text3 = \"I didn't like the movie. It was boring\"\n",
    "\n",
    "result = sentiment_classifier(text3)\n",
    "\n",
    "# Output the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ce2c37",
   "metadata": {},
   "source": [
    "### Expected Result\n",
    "\n",
    "Ignore any warnings <br><br>\n",
    "\n",
    "[{'label': 'POSITIVE', 'score': 0.9984171390533447}]<br>\n",
    "[{'label': 'NEGATIVE', 'score': 0.999295711517334}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83725d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
